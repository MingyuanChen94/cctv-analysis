{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoEnhancer:\n",
    "    def __init__(self, input_dir, output_dir, target_resolution=(1080, 1920), target_fps=15):\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.target_resolution = target_resolution\n",
    "        self.target_fps = target_fps\n",
    "        self.device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize frame interpolation\n",
    "        try:\n",
    "            # Ensure torch-rife is installed\n",
    "            import torch_rife\n",
    "            self.rife_model = torch_rife.RIFE(model_version='4.6')  # Explicitly specify version\n",
    "            print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "            print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "            print(f\"Using device: {self.device}\")\n",
    "            \n",
    "            if self.device == 'mps':\n",
    "                # For M1/M2 Macs\n",
    "                self.rife_model.to('cpu')  # Use CPU for more stable operation on M1/M2\n",
    "                print(\"Using CPU for frame interpolation on Apple Silicon\")\n",
    "            else:\n",
    "                self.rife_model.to(self.device)\n",
    "                print(f\"RIFE model moved to {self.device}\")\n",
    "            \n",
    "            # Test the model with a small dummy input\n",
    "            with torch.no_grad():\n",
    "                dummy1 = torch.zeros(1, 3, 64, 64).to(self.device if self.device != 'mps' else 'cpu')\n",
    "                dummy2 = torch.zeros(1, 3, 64, 64).to(self.device if self.device != 'mps' else 'cpu')\n",
    "                _ = self.rife_model.inference(dummy1, dummy2)\n",
    "                print(\"Successfully tested RIFE model\")\n",
    "                \n",
    "        except ImportError:\n",
    "            print(\"torch-rife not found. Installing...\")\n",
    "            import subprocess\n",
    "            try:\n",
    "                subprocess.check_call(['pip', 'install', 'torch-rife'])\n",
    "                import torch_rife\n",
    "                self.rife_model = torch_rife.RIFE(model_version='4.6')\n",
    "                print(\"Successfully installed and loaded torch-rife\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error installing torch-rife: {e}\")\n",
    "                self.rife_model = None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing frame interpolation: {e}\")\n",
    "            print(\"Detailed error information:\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            self.rife_model = None\n",
    "\n",
    "    def enhance_frame(self, frame):\n",
    "        \"\"\"Upscale a single frame using Lanczos interpolation\"\"\"\n",
    "        # Convert frame to BGR for OpenCV\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Upscale using Lanczos interpolation\n",
    "        upscaled = cv2.resize(frame, \n",
    "                            (self.target_resolution[1], self.target_resolution[0]),\n",
    "                            interpolation=cv2.INTER_LANCZOS4)\n",
    "        \n",
    "        # Convert back to RGB\n",
    "        return cv2.cvtColor(upscaled, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    def interpolate_frames(self, frame1, frame2):\n",
    "        \"\"\"Generate intermediate frame using RIFE or frame blending\"\"\"\n",
    "        if self.rife_model is None:\n",
    "            # Simple frame blending as fallback\n",
    "            return cv2.addWeighted(frame1, 0.5, frame2, 0.5, 0)\n",
    "            \n",
    "        try:\n",
    "            # Convert frames to tensors\n",
    "            frame1 = torch.from_numpy(frame1).permute(2, 0, 1).float() / 255.0\n",
    "            frame2 = torch.from_numpy(frame2).permute(2, 0, 1).float() / 255.0\n",
    "            \n",
    "            # Add batch dimension and move to device\n",
    "            frame1 = frame1.unsqueeze(0)\n",
    "            frame2 = frame2.unsqueeze(0)\n",
    "            \n",
    "            if self.device != 'cpu':\n",
    "                frame1 = frame1.to(self.device)\n",
    "                frame2 = frame2.to(self.device)\n",
    "            \n",
    "            # Generate intermediate frame\n",
    "            with torch.no_grad():\n",
    "                middle = self.rife_model.inference(frame1, frame2)\n",
    "            \n",
    "            # Convert back to numpy array\n",
    "            if self.device != 'cpu':\n",
    "                middle = middle.cpu()\n",
    "            middle = (middle[0].numpy().transpose(1, 2, 0) * 255).astype(np.uint8)\n",
    "            return middle\n",
    "        except Exception as e:\n",
    "            print(f\"Frame interpolation failed, falling back to frame blending: {e}\")\n",
    "            return cv2.addWeighted(frame1, 0.5, frame2, 0.5, 0)\n",
    "\n",
    "    def process_video(self, input_path):\n",
    "        \"\"\"Process a single video file\"\"\"\n",
    "        filename = os.path.basename(input_path)\n",
    "        output_path = os.path.join(self.output_dir, f\"{filename}\")\n",
    "        \n",
    "        print(f\"\\nProcessing {filename}\")\n",
    "        \n",
    "        # Load video\n",
    "        clip = VideoFileClip(input_path)\n",
    "        \n",
    "        # Calculate frames needed for target fps\n",
    "        original_duration = clip.duration\n",
    "        original_frames = list(clip.iter_frames())\n",
    "        \n",
    "        enhanced_frames = []\n",
    "        total_frames = len(original_frames)\n",
    "        \n",
    "        # Process frames with progress bar\n",
    "        with tqdm(total=total_frames, desc=\"Processing frames\") as pbar:\n",
    "            # Enhance resolution of original frames\n",
    "            for i, frame in enumerate(original_frames):\n",
    "                enhanced = self.enhance_frame(frame)\n",
    "                enhanced_frames.append(enhanced)\n",
    "                \n",
    "                # Interpolate frames if needed and RIFE is available\n",
    "                if i < total_frames - 1 and self.rife_model is not None:\n",
    "                    try:\n",
    "                        next_frame = self.enhance_frame(original_frames[i + 1])\n",
    "                        middle_frame = self.interpolate_frames(enhanced, next_frame)\n",
    "                        if middle_frame is not None:\n",
    "                            enhanced_frames.append(middle_frame)\n",
    "                    except Exception as e:\n",
    "                        print(f\"\\nFrame interpolation error at frame {i}: {e}\")\n",
    "                        print(\"Continuing without interpolation for this frame pair\")\n",
    "                \n",
    "                pbar.update(1)\n",
    "                \n",
    "        print(f\"\\nTotal frames after processing: {len(enhanced_frames)}\")\n",
    "        print(f\"Final FPS will be: {len(enhanced_frames)/original_duration:.2f}\")\n",
    "        \n",
    "        # Create new video clip\n",
    "        from moviepy.editor import ImageSequenceClip\n",
    "        enhanced_clip = ImageSequenceClip(enhanced_frames, fps=self.target_fps)\n",
    "        \n",
    "        print(f\"Writing enhanced video to {output_path}\")\n",
    "        \n",
    "        # Write output video\n",
    "        enhanced_clip.write_videofile(output_path, \n",
    "                                    codec='libx264', \n",
    "                                    audio=False,  # Remove if you want to keep audio\n",
    "                                    threads=8,    # Utilize multiple CPU cores\n",
    "                                    preset='medium',\n",
    "                                    verbose=False,\n",
    "                                    logger=None)\n",
    "        \n",
    "        # Clean up\n",
    "        clip.close()\n",
    "        enhanced_clip.close()\n",
    "\n",
    "    def process_directory(self):\n",
    "        \"\"\"Process all videos in the input directory\"\"\"\n",
    "        video_files = glob.glob(os.path.join(self.input_dir, \"*.[mM][pP]4\"))\n",
    "        video_files.extend(glob.glob(os.path.join(self.input_dir, \"*.[mM][oO][vV]\")))\n",
    "        \n",
    "        print(f\"Found {len(video_files)} videos to process\")\n",
    "        for video_file in video_files:\n",
    "            try:\n",
    "                self.process_video(video_file)\n",
    "                print(f\"Successfully processed {video_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Error initializing frame interpolation: No module named 'torch_rife'\n",
      "Frame interpolation will be disabled - using simple frame duplication\n",
      "To enable frame interpolation, install torch-rife: pip install torch-rife\n",
      "Found 2 videos to process\n",
      "\n",
      "Processing Camera_2_20241101.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  61%|██████    | 2187/3602 [00:57<00:38, 37.08it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_dir = os.path.join(os.path.expanduser(\"~\"), \"Library\", \"CloudStorage\", \n",
    "                              \"OneDrive-UniversityofExeter\", \"Documents\", \"VISIONARY\", \n",
    "                              \"Durham Experiment\", \"test_data\")\n",
    "output_dir = os.path.join(os.path.expanduser(\"~\"), \"Library\", \"CloudStorage\", \n",
    "                              \"OneDrive-UniversityofExeter\", \"Documents\", \"VISIONARY\", \n",
    "                              \"Durham Experiment\", \"enh_data\")\n",
    "\n",
    "target_resolution = (1080, 1920)  # Height, Width\n",
    "target_fps = 15\n",
    "\n",
    "# Initialize and run enhancer\n",
    "enhancer = VideoEnhancer(input_dir, output_dir, target_resolution, target_fps)\n",
    "enhancer.process_directory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reid-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
