{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torchreid\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import scipy.spatial.distance as distance\n",
    "\n",
    "class TrackingState:\n",
    "    ACTIVE = 'active'          # Fully visible\n",
    "    OCCLUDED = 'occluded'      # Temporarily hidden\n",
    "    TENTATIVE = 'tentative'    # New track\n",
    "    LOST = 'lost'              # Missing too long\n",
    "\n",
    "class PersonTracker:\n",
    "    def __init__(self, video_path, output_dir=\"tracked_persons\"):\n",
    "        # Initialize YOLO model\n",
    "        self.detector = YOLO(\"yolo11x.pt\")\n",
    "        \n",
    "        # Initialize ReID model\n",
    "        self.reid_model = torchreid.models.build_model(\n",
    "            name='osnet_x1_0',\n",
    "            num_classes=1000,\n",
    "            pretrained=True\n",
    "        )\n",
    "        self.reid_model = self.reid_model.cuda() if torch.cuda.is_available() else self.reid_model\n",
    "        self.reid_model.eval()\n",
    "        \n",
    "        # Initialize video capture\n",
    "        self.cap = cv2.VideoCapture(video_path)\n",
    "        self.frame_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.frame_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.fps = int(self.cap.get(cv2.CAP_PROP_FPS))\n",
    "        \n",
    "        # Create output directory\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize tracking variables\n",
    "        self.active_tracks = {}  # Currently active tracks\n",
    "        self.person_features = {}  # Historical features for each ID\n",
    "        self.person_timestamps = {}  # Timestamp information\n",
    "        self.next_id = 0\n",
    "        \n",
    "        # Tracking parameters\n",
    "        self.similarity_threshold = 0.7\n",
    "        self.max_disappeared = self.fps * 2  # Max frames to keep track without detection\n",
    "        self.min_detection_confidence = 0.5\n",
    "        self.feature_weight = 0.4   # Weight for ReID features in matching\n",
    "        self.position_weight = 0.3  # Weight for absolute position (IoU)\n",
    "        self.motion_weight = 0.3    # Weight for relative motion prediction\n",
    "        \n",
    "    def extract_features(self, person_crop):\n",
    "        \"\"\"Extract ReID features from person crop\"\"\"\n",
    "        try:\n",
    "            # Preprocess image for ReID\n",
    "            img = cv2.resize(person_crop, (128, 256))\n",
    "            img = torch.from_numpy(img).float()\n",
    "            img = img.permute(2, 0, 1).unsqueeze(0)\n",
    "            if torch.cuda.is_available():\n",
    "                img = img.cuda()\n",
    "                \n",
    "            # Extract features\n",
    "            with torch.no_grad():\n",
    "                features = self.reid_model(img)\n",
    "            return features.cpu().numpy()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting features: {e}\")\n",
    "            return None\n",
    "            \n",
    "    def calculate_box_center(self, box):\n",
    "        \"\"\"Calculate center point of a bounding box\"\"\"\n",
    "        return [(box[0] + box[2]) / 2, (box[1] + box[3]) / 2]\n",
    "\n",
    "    def calculate_velocity(self, current_box, previous_box):\n",
    "        \"\"\"Calculate velocity vector between two boxes\"\"\"\n",
    "        current_center = self.calculate_box_center(current_box)\n",
    "        previous_center = self.calculate_box_center(previous_box)\n",
    "        return [current_center[0] - previous_center[0], \n",
    "                current_center[1] - previous_center[1]]\n",
    "\n",
    "    def predict_next_position(self, box, velocity):\n",
    "        \"\"\"Predict next position based on current position and velocity\"\"\"\n",
    "        center = self.calculate_box_center(box)\n",
    "        predicted_center = [center[0] + velocity[0], center[1] + velocity[1]]\n",
    "        width = box[2] - box[0]\n",
    "        height = box[3] - box[1]\n",
    "        return [predicted_center[0] - width/2, predicted_center[1] - height/2,\n",
    "                predicted_center[0] + width/2, predicted_center[1] + height/2]\n",
    "\n",
    "    def calculate_motion_similarity(self, current_boxes, tracked_boxes, tracked_velocities):\n",
    "        \"\"\"Calculate motion-based similarity\"\"\"\n",
    "        n_detections = len(current_boxes)\n",
    "        n_tracks = len(tracked_boxes)\n",
    "        motion_sim = np.zeros((n_detections, n_tracks))\n",
    "        \n",
    "        for i, current_box in enumerate(current_boxes):\n",
    "            current_center = self.calculate_box_center(current_box)\n",
    "            for j, (tracked_box, velocity) in enumerate(zip(tracked_boxes, tracked_velocities)):\n",
    "                # Predict where the tracked box should be\n",
    "                predicted_box = self.predict_next_position(tracked_box, velocity)\n",
    "                predicted_center = self.calculate_box_center(predicted_box)\n",
    "                \n",
    "                # Calculate distance between prediction and actual position\n",
    "                distance = np.sqrt(\n",
    "                    (current_center[0] - predicted_center[0])**2 +\n",
    "                    (current_center[1] - predicted_center[1])**2\n",
    "                )\n",
    "                # Convert distance to similarity (closer = more similar)\n",
    "                motion_sim[i, j] = np.exp(-distance / 100.0)  # 100 is a scaling factor\n",
    "                \n",
    "        return motion_sim\n",
    "\n",
    "    def detect_occlusion(self, box1, box2):\n",
    "        \"\"\"\n",
    "        Detect if box1 is occluded by box2.\n",
    "        Returns: \n",
    "            - is_occluded (bool): True if box1 is occluded by box2\n",
    "            - occlusion_score (float): Degree of occlusion (0 to 1)\n",
    "        \"\"\"\n",
    "        # Calculate IoU\n",
    "        iou = self.calculate_iou(box1, box2)\n",
    "        \n",
    "        # Calculate centers and areas\n",
    "        center1 = self.calculate_box_center(box1)\n",
    "        center2 = self.calculate_box_center(box2)\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        \n",
    "        # Calculate vertical position (y-coordinate)\n",
    "        y1 = box1[3]  # bottom of box1\n",
    "        y2 = box2[3]  # bottom of box2\n",
    "        \n",
    "        # Factors that suggest box1 is behind box2:\n",
    "        # 1. Significant overlap\n",
    "        overlap_factor = 1.0 if iou > 0.3 else 0.0\n",
    "        \n",
    "        # 2. Box2 is closer to camera (generally larger and lower in frame)\n",
    "        size_factor = 1.0 if area2 > area1 else 0.0\n",
    "        position_factor = 1.0 if y2 > y1 else 0.0\n",
    "        \n",
    "        # 3. Box1 is partially contained within box2\n",
    "        contained_horizontally = (\n",
    "            (box1[0] > box2[0] and box1[0] < box2[2]) or\n",
    "            (box1[2] > box2[0] and box1[2] < box2[2])\n",
    "        )\n",
    "        contained_vertically = (\n",
    "            (box1[1] > box2[1] and box1[1] < box2[3]) or\n",
    "            (box1[3] > box2[1] and box1[3] < box2[3])\n",
    "        )\n",
    "        containment_factor = 1.0 if (contained_horizontally and contained_vertically) else 0.0\n",
    "        \n",
    "        # Calculate occlusion score (weighted combination of factors)\n",
    "        occlusion_score = (\n",
    "            0.4 * overlap_factor +\n",
    "            0.2 * size_factor +\n",
    "            0.2 * position_factor +\n",
    "            0.2 * containment_factor\n",
    "        )\n",
    "        \n",
    "        # Determine if occluded based on score threshold\n",
    "        is_occluded = occlusion_score > 0.5\n",
    "        \n",
    "        return is_occluded, occlusion_score\n",
    "\n",
    "    def calculate_similarity_matrix(self, current_features, current_boxes, tracked_features, tracked_boxes):\n",
    "        \"\"\"Calculate similarity matrix combining appearance, position, and motion\"\"\"\n",
    "        n_detections = len(current_features)\n",
    "        n_tracks = len(tracked_features)\n",
    "        \n",
    "        if n_detections == 0 or n_tracks == 0:\n",
    "            return np.array([])\n",
    "            \n",
    "        # Calculate appearance similarity\n",
    "        appearance_sim = 1 - distance.cdist(\n",
    "            np.array([f.flatten() for f in current_features]), \n",
    "            np.array([f.flatten() for f in tracked_features]), \n",
    "            metric='cosine'\n",
    "        )\n",
    "        \n",
    "        # Calculate position similarity using IoU\n",
    "        position_sim = np.zeros((n_detections, n_tracks))\n",
    "        for i, box1 in enumerate(current_boxes):\n",
    "            for j, box2 in enumerate(tracked_boxes):\n",
    "                position_sim[i, j] = self.calculate_iou(box1, box2)\n",
    "        \n",
    "        # Calculate velocities for tracked objects\n",
    "        tracked_velocities = []\n",
    "        for track_id in list(self.active_tracks.keys())[:n_tracks]:\n",
    "            if 'previous_box' in self.active_tracks[track_id]:\n",
    "                velocity = self.calculate_velocity(\n",
    "                    self.active_tracks[track_id]['box'],\n",
    "                    self.active_tracks[track_id]['previous_box']\n",
    "                )\n",
    "            else:\n",
    "                velocity = [0, 0]  # No velocity for new tracks\n",
    "            tracked_velocities.append(velocity)\n",
    "        \n",
    "        # Calculate motion similarity\n",
    "        motion_sim = self.calculate_motion_similarity(current_boxes, tracked_boxes, tracked_velocities)\n",
    "        \n",
    "        # Combine all similarities\n",
    "        similarity_matrix = (\n",
    "            self.feature_weight * appearance_sim + \n",
    "            self.position_weight * position_sim +\n",
    "            self.motion_weight * motion_sim\n",
    "        )\n",
    "        \n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_iou(box1, box2):\n",
    "        \"\"\"Calculate IoU between two boxes\"\"\"\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "        \n",
    "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        union = area1 + area2 - intersection\n",
    "        \n",
    "        return intersection / (union + 1e-6)\n",
    "    \n",
    "    def update_feature_history(self, track_id, features):\n",
    "        \"\"\"Maintain rolling window of recent features\"\"\"\n",
    "        self.appearance_history[track_id].append(features)\n",
    "        if len(self.appearance_history[track_id]) > self.max_history_length:\n",
    "            self.appearance_history[track_id].pop(0)\n",
    "            \n",
    "        # Update feature representation using exponential moving average\n",
    "        if track_id in self.person_features:\n",
    "            alpha = 0.7  # Weight for historical features\n",
    "            current_features = self.person_features[track_id]\n",
    "            updated_features = alpha * current_features + (1 - alpha) * features\n",
    "            self.person_features[track_id] = updated_features\n",
    "        else:\n",
    "            self.person_features[track_id] = features\n",
    "\n",
    "    def recover_lost_tracklet(self, features, current_box, frame_time):\n",
    "        \"\"\"Attempt to recover lost tracks\"\"\"\n",
    "        best_match_id = None\n",
    "        best_match_score = 0\n",
    "        \n",
    "        # Check recently lost tracks\n",
    "        lost_tracks_to_remove = []\n",
    "        for lost_id, lost_info in self.lost_tracks.items():\n",
    "            # Skip if lost track is too old\n",
    "            if frame_time - lost_info['last_seen'] > self.max_lost_age:\n",
    "                lost_tracks_to_remove.append(lost_id)\n",
    "                continue\n",
    "                \n",
    "            # Calculate appearance similarity\n",
    "            lost_features = lost_info['features']\n",
    "            appearance_sim = 1 - distance.cosine(features.flatten(), lost_features.flatten())\n",
    "            \n",
    "            # Calculate position similarity based on predicted movement\n",
    "            predicted_box = self.predict_next_position(\n",
    "                lost_info['box'],\n",
    "                lost_info['velocity']\n",
    "            )\n",
    "            position_sim = self.calculate_iou(current_box, predicted_box)\n",
    "            \n",
    "            # Combine similarities\n",
    "            match_score = (\n",
    "                self.feature_weight * appearance_sim +\n",
    "                self.position_weight * position_sim\n",
    "            )\n",
    "            \n",
    "            # Check temporal consistency\n",
    "            if match_score > 0.6 and match_score > best_match_score:\n",
    "                best_match_score = match_score\n",
    "                best_match_id = lost_id\n",
    "        \n",
    "        # Clean up old lost tracks\n",
    "        for lost_id in lost_tracks_to_remove:\n",
    "            del self.lost_tracks[lost_id]\n",
    "            \n",
    "        return best_match_id if best_match_score > 0.6 else None\n",
    "\n",
    "    def update_tracks(self, frame, detections, frame_time):\n",
    "        \"\"\"Update tracks with new detections\"\"\"\n",
    "        current_boxes = []\n",
    "        current_features = []\n",
    "        \n",
    "        # Process new detections\n",
    "        for box, conf in detections:\n",
    "            if conf < self.min_detection_confidence:\n",
    "                continue\n",
    "                \n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            person_crop = frame[y1:y2, x1:x2]\n",
    "            if person_crop.size == 0:\n",
    "                continue\n",
    "                \n",
    "            features = self.extract_features(person_crop)\n",
    "            if features is not None:\n",
    "                current_boxes.append([x1, y1, x2, y2])\n",
    "                current_features.append(features)\n",
    "        \n",
    "        # Get tracked boxes and features\n",
    "        tracked_boxes = []\n",
    "        tracked_features = []\n",
    "        tracked_ids = []\n",
    "        \n",
    "        for track_id, track_info in self.active_tracks.items():\n",
    "            tracked_boxes.append(track_info['box'])\n",
    "            tracked_features.append(track_info['features'])\n",
    "            tracked_ids.append(track_id)\n",
    "        \n",
    "        # Calculate similarity matrix\n",
    "        similarity_matrix = self.calculate_similarity_matrix(\n",
    "            current_features, current_boxes,\n",
    "            tracked_features, tracked_boxes\n",
    "        )\n",
    "        \n",
    "        # Perform matching\n",
    "        matched_indices = []\n",
    "        if similarity_matrix.size > 0:\n",
    "            row_ind, col_ind = linear_sum_assignment(-similarity_matrix)\n",
    "            matched_indices = list(zip(row_ind, col_ind))\n",
    "        \n",
    "        # Process matches\n",
    "        unmatched_detections = []\n",
    "        matched_track_ids = set()\n",
    "        \n",
    "        for detection_idx, track_idx in matched_indices:\n",
    "            similarity = similarity_matrix[detection_idx, track_idx]\n",
    "            if similarity >= self.similarity_threshold:\n",
    "                track_id = tracked_ids[track_idx]\n",
    "                matched_track_ids.add(track_id)\n",
    "                \n",
    "                # Update track\n",
    "                self.active_tracks[track_id].update({\n",
    "                    'previous_box': self.active_tracks[track_id]['box'],\n",
    "                    'box': current_boxes[detection_idx],\n",
    "                    'features': current_features[detection_idx],\n",
    "                    'last_seen': frame_time,\n",
    "                    'disappeared': 0\n",
    "                })\n",
    "                \n",
    "                # Update timestamps\n",
    "                self.person_timestamps[track_id]['last_appearance'] = frame_time\n",
    "                \n",
    "                # Save person image\n",
    "                self.save_person_image(track_id, \n",
    "                    frame[current_boxes[detection_idx][1]:current_boxes[detection_idx][3],\n",
    "                          current_boxes[detection_idx][0]:current_boxes[detection_idx][2]])\n",
    "            else:\n",
    "                unmatched_detections.append(detection_idx)\n",
    "        \n",
    "        # Add unmatched detections as new tracks\n",
    "        for detection_idx in range(len(current_features)):\n",
    "            if not any(detection_idx == m[0] for m in matched_indices):\n",
    "                new_id = self.next_id\n",
    "                self.next_id += 1\n",
    "                \n",
    "                self.active_tracks[new_id] = {\n",
    "                    'state': TrackingState.TENTATIVE,\n",
    "                    'occlusion_counter': 0,\n",
    "                    'box': current_boxes[detection_idx],\n",
    "                    'features': current_features[detection_idx],\n",
    "                    'last_seen': frame_time,\n",
    "                    'disappeared': 0,\n",
    "                    'velocity': [0, 0]  # Initialize velocity for new tracks\n",
    "                }\n",
    "                \n",
    "                self.person_features[new_id] = [current_features[detection_idx]]\n",
    "                self.person_timestamps[new_id] = {\n",
    "                    'first_appearance': frame_time,\n",
    "                    'last_appearance': frame_time\n",
    "                }\n",
    "                \n",
    "                # Save person image\n",
    "                self.save_person_image(new_id, \n",
    "                    frame[current_boxes[detection_idx][1]:current_boxes[detection_idx][3],\n",
    "                          current_boxes[detection_idx][0]:current_boxes[detection_idx][2]])\n",
    "        \n",
    "        # Update disappeared tracks\n",
    "        current_time = frame_time\n",
    "        tracks_to_remove = []\n",
    "        \n",
    "        for track_id in self.active_tracks:\n",
    "            if track_id not in matched_track_ids:\n",
    "                self.active_tracks[track_id]['disappeared'] += 1\n",
    "                if self.active_tracks[track_id]['disappeared'] > self.max_disappeared:\n",
    "                    tracks_to_remove.append(track_id)\n",
    "        \n",
    "        # Remove old tracks\n",
    "        for track_id in tracks_to_remove:\n",
    "            del self.active_tracks[track_id]\n",
    "    \n",
    "    def save_person_image(self, person_id, frame):\n",
    "        \"\"\"Save person image to output directory\"\"\"\n",
    "        person_dir = os.path.join(self.output_dir, f\"person_{person_id}\")\n",
    "        os.makedirs(person_dir, exist_ok=True)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "        cv2.imwrite(os.path.join(person_dir, f\"{timestamp}.jpg\"), frame)\n",
    "    \n",
    "    def process_video(self):\n",
    "        frame_count = 0\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            frame_time = frame_count / self.fps\n",
    "            frame_count += 1\n",
    "            \n",
    "            # Detect persons using YOLO\n",
    "            results = self.detector(frame, classes=[0])  # class 0 is person\n",
    "            \n",
    "            # Process detections\n",
    "            detections = []\n",
    "            for result in results:\n",
    "                boxes = result.boxes.cpu().numpy()\n",
    "                for box in boxes:\n",
    "                    detections.append((box.xyxy[0], box.conf[0]))\n",
    "            \n",
    "            # Update tracking\n",
    "            self.update_tracks(frame, detections, frame_time)\n",
    "            \n",
    "            # Visualize results\n",
    "            for track_id, track_info in self.active_tracks.items():\n",
    "                box = track_info['box']\n",
    "                cv2.rectangle(frame, (int(box[0]), int(box[1])), \n",
    "                            (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"ID: {track_id}\", \n",
    "                          (int(box[0]), int(box[1])-10),\n",
    "                          cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            \n",
    "            # Display frame\n",
    "            cv2.imshow('Tracking', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        return self.generate_report()\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate tracking report\"\"\"\n",
    "        report = {\n",
    "            'total_unique_persons': self.next_id,\n",
    "            'person_details': {}\n",
    "        }\n",
    "        \n",
    "        for person_id in self.person_timestamps.keys():\n",
    "            report['person_details'][person_id] = {\n",
    "                'first_appearance': self.person_timestamps[person_id]['first_appearance'],\n",
    "                'last_appearance': self.person_timestamps[person_id]['last_appearance'],\n",
    "                'duration': self.person_timestamps[person_id]['last_appearance'] - \n",
    "                          self.person_timestamps[person_id]['first_appearance'],\n",
    "                'image_path': os.path.join(self.output_dir, f\"person_{person_id}\")\n",
    "            }\n",
    "            \n",
    "        return report\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"your_video.mp4\"\n",
    "    tracker = PersonTracker(video_path)\n",
    "    report = tracker.process_video()\n",
    "    print(f\"Total unique persons detected: {report['total_unique_persons']}\")\n",
    "    for person_id, details in report['person_details'].items():\n",
    "        print(f\"\\nPerson ID: {person_id}\")\n",
    "        print(f\"First appearance: {details['first_appearance']:.2f}s\")\n",
    "        print(f\"Last appearance: {details['last_appearance']:.2f}s\")\n",
    "        print(f\"Duration in video: {details['duration']:.2f}s\")\n",
    "        print(f\"Images saved in: {details['image_path']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reid-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
