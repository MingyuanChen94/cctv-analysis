{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCTV Analysis\n",
    "This notebook demonstrates the capabilities of our CCTV analysis system for multi-camera person tracking and analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mc1159\\AppData\\Local\\anaconda3\\envs\\cctv-analysis\\lib\\site-packages\\torchreid\\reid\\metrics\\rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torchreid\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import scipy.spatial.distance as distance\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\mc1159\\OneDrive - University of Exeter\\Documents\\VISIONARY\\Durham Experiment\\test_data\n"
     ]
    }
   ],
   "source": [
    "# Set the working directory\n",
    "working_directory = os.path.join('C:\\\\Users', 'mc1159', 'OneDrive - University of Exeter',\n",
    "                                 'Documents', 'VISIONARY', 'Durham Experiment', 'test_data')\n",
    "# working_directory = os.path.join('C:\\\\Users', 'mc1159', 'OneDrive - University of Exeter',\n",
    "#                                'Documents', 'VISIONARY', 'Durham Experiment', 'processed_data')\n",
    "# working_directory = os.path.join(os.path.expanduser(\"~\"), \"Library\", \"CloudStorage\",\n",
    "\n",
    "\n",
    "#                               \"OneDrive-UniversityofExeter\", \"Documents\", \"VISIONARY\",\n",
    "\n",
    "\n",
    "#                               \"Durham Experiment\", \"test_data\")\n",
    "\n",
    "\n",
    "# working_directory = os.path.join(os.path.expanduser(\"~\"), \"Library\", \"CloudStorage\",\n",
    "\n",
    "\n",
    "#                               \"OneDrive-UniversityofExeter\", \"Documents\", \"VISIONARY\",\n",
    "\n",
    "\n",
    "#                               \"Durham Experiment\", \"processed_data_3\")\n",
    "\n",
    "\n",
    "os.chdir(working_directory)\n",
    "\n",
    "\n",
    "# Verify the current working directory\n",
    "\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Camera_1_20241101.mp4', 'Camera_2_20241101.mp4']\n"
     ]
    }
   ],
   "source": [
    "# Get the .mp4 files in the folder\n",
    "mp4_files = list(Path(working_directory).glob(\"*.mp4\"))\n",
    "# Print the .mp4 files without showing the parent directories\n",
    "print([file.name for file in mp4_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 1 files sorted by date: ['Camera_1_20241101.mp4']\n",
      "Camera 2 files sorted by date: ['Camera_2_20241101.mp4']\n"
     ]
    }
   ],
   "source": [
    "# Filter the files for Camera_1 and Camera_2\n",
    "camera_1_files = [\n",
    "    file for file in mp4_files if file.name.startswith(\"Camera_1_\")]\n",
    "camera_2_files = [\n",
    "    file for file in mp4_files if file.name.startswith(\"Camera_2_\")]\n",
    "\n",
    "# Sort the files by date extracted from the filename\n",
    "camera_1_files_sorted = sorted(\n",
    "    camera_1_files, key=lambda x: x.stem.split('_')[-1])\n",
    "camera_2_files_sorted = sorted(\n",
    "    camera_2_files, key=lambda x: x.stem.split('_')[-1])\n",
    "\n",
    "print(\"Camera 1 files sorted by date:\", [\n",
    "      file.name for file in camera_1_files_sorted])\n",
    "print(\"Camera 2 files sorted by date:\", [\n",
    "      file.name for file in camera_2_files_sorted])\n",
    "\n",
    "del mp4_files, camera_1_files, camera_2_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = camera_1_files_sorted[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initate Video Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingState:\n",
    "    ACTIVE = 'active'          # Fully visible\n",
    "    OCCLUDED = 'occluded'      # Temporarily hidden\n",
    "    TENTATIVE = 'tentative'    # New track\n",
    "    LOST = 'lost'              # Missing too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingState:\n",
    "    ACTIVE = 'active'          # Fully visible\n",
    "    OCCLUDED = 'occluded'      # Temporarily hidden\n",
    "    TENTATIVE = 'tentative'    # New track\n",
    "    LOST = 'lost'              # Missing too long\n",
    "\n",
    "\n",
    "class PersonTracker:\n",
    "    def __init__(self, video_path, output_dir=\"tracked_persons\"):\n",
    "        # Initialize YOLO model\n",
    "        self.detector = YOLO(\"yolo11x.pt\")\n",
    "\n",
    "        # Initialize ReID model\n",
    "        self.reid_model = torchreid.models.build_model(\n",
    "            name='osnet_x1_0',\n",
    "            num_classes=1000,\n",
    "            pretrained=True\n",
    "        )\n",
    "        self.reid_model = self.reid_model.cuda(\n",
    "        ) if torch.cuda.is_available() else self.reid_model\n",
    "        self.reid_model.eval()\n",
    "\n",
    "        # Initialize video capture\n",
    "        self.cap = cv2.VideoCapture(video_path)\n",
    "        self.frame_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.frame_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.fps = int(self.cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "        # Create output directory\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Initialize tracking variables\n",
    "        self.active_tracks = {}  # Currently active tracks\n",
    "        self.person_features = {}  # Historical features for each ID\n",
    "        self.person_timestamps = {}  # Timestamp information\n",
    "        self.next_id = 0\n",
    "\n",
    "        # Tracking parameters\n",
    "        self.similarity_threshold = 0.7\n",
    "        self.max_disappeared = self.fps * 2  # Max frames to keep track without detection\n",
    "        self.min_detection_confidence = 0.5\n",
    "        self.feature_weight = 0.4   # Weight for ReID features in matching\n",
    "        self.position_weight = 0.3  # Weight for absolute position (IoU)\n",
    "        self.motion_weight = 0.3    # Weight for relative motion prediction\n",
    "\n",
    "    def extract_features(self, person_crop):\n",
    "        \"\"\"Extract ReID features from person crop\"\"\"\n",
    "        try:\n",
    "            # Preprocess image for ReID\n",
    "            img = cv2.resize(person_crop, (128, 256))\n",
    "            img = torch.from_numpy(img).float()\n",
    "            img = img.permute(2, 0, 1).unsqueeze(0)\n",
    "            if torch.cuda.is_available():\n",
    "                img = img.cuda()\n",
    "\n",
    "            # Extract features\n",
    "            with torch.no_grad():\n",
    "                features = self.reid_model(img)\n",
    "            return features.cpu().numpy()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting features: {e}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_box_center(self, box):\n",
    "        \"\"\"Calculate center point of a bounding box\"\"\"\n",
    "        return [(box[0] + box[2]) / 2, (box[1] + box[3]) / 2]\n",
    "\n",
    "    def calculate_velocity(self, current_box, previous_box):\n",
    "        \"\"\"Calculate velocity vector between two boxes\"\"\"\n",
    "        current_center = self.calculate_box_center(current_box)\n",
    "        previous_center = self.calculate_box_center(previous_box)\n",
    "        return [current_center[0] - previous_center[0],\n",
    "                current_center[1] - previous_center[1]]\n",
    "\n",
    "    def predict_next_position(self, box, velocity):\n",
    "        \"\"\"Predict next position based on current position and velocity\"\"\"\n",
    "        center = self.calculate_box_center(box)\n",
    "        predicted_center = [center[0] + velocity[0], center[1] + velocity[1]]\n",
    "        width = box[2] - box[0]\n",
    "        height = box[3] - box[1]\n",
    "        return [predicted_center[0] - width/2, predicted_center[1] - height/2,\n",
    "                predicted_center[0] + width/2, predicted_center[1] + height/2]\n",
    "\n",
    "    def calculate_motion_similarity(self, current_boxes, tracked_boxes, tracked_velocities):\n",
    "        \"\"\"Calculate motion-based similarity\"\"\"\n",
    "        n_detections = len(current_boxes)\n",
    "        n_tracks = len(tracked_boxes)\n",
    "        motion_sim = np.zeros((n_detections, n_tracks))\n",
    "\n",
    "        for i, current_box in enumerate(current_boxes):\n",
    "            current_center = self.calculate_box_center(current_box)\n",
    "            for j, (tracked_box, velocity) in enumerate(zip(tracked_boxes, tracked_velocities)):\n",
    "                # Predict where the tracked box should be\n",
    "                predicted_box = self.predict_next_position(\n",
    "                    tracked_box, velocity)\n",
    "                predicted_center = self.calculate_box_center(predicted_box)\n",
    "\n",
    "                # Calculate distance between prediction and actual position\n",
    "                distance = np.sqrt(\n",
    "                    (current_center[0] - predicted_center[0])**2 +\n",
    "                    (current_center[1] - predicted_center[1])**2\n",
    "                )\n",
    "                # Convert distance to similarity (closer = more similar)\n",
    "                # 100 is a scaling factor\n",
    "                motion_sim[i, j] = np.exp(-distance / 100.0)\n",
    "\n",
    "        return motion_sim\n",
    "\n",
    "    def detect_occlusion(self, box1, box2):\n",
    "        \"\"\"\n",
    "        Detect if box1 is occluded by box2.\n",
    "        Returns: \n",
    "            - is_occluded (bool): True if box1 is occluded by box2\n",
    "            - occlusion_score (float): Degree of occlusion (0 to 1)\n",
    "        \"\"\"\n",
    "        # Calculate IoU\n",
    "        iou = self.calculate_iou(box1, box2)\n",
    "\n",
    "        # Calculate centers and areas\n",
    "        center1 = self.calculate_box_center(box1)\n",
    "        center2 = self.calculate_box_center(box2)\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "        # Calculate vertical position (y-coordinate)\n",
    "        y1 = box1[3]  # bottom of box1\n",
    "        y2 = box2[3]  # bottom of box2\n",
    "\n",
    "        # Factors that suggest box1 is behind box2:\n",
    "        # 1. Significant overlap\n",
    "        overlap_factor = 1.0 if iou > 0.3 else 0.0\n",
    "\n",
    "        # 2. Box2 is closer to camera (generally larger and lower in frame)\n",
    "        size_factor = 1.0 if area2 > area1 else 0.0\n",
    "        position_factor = 1.0 if y2 > y1 else 0.0\n",
    "\n",
    "        # 3. Box1 is partially contained within box2\n",
    "        contained_horizontally = (\n",
    "            (box1[0] > box2[0] and box1[0] < box2[2]) or\n",
    "            (box1[2] > box2[0] and box1[2] < box2[2])\n",
    "        )\n",
    "        contained_vertically = (\n",
    "            (box1[1] > box2[1] and box1[1] < box2[3]) or\n",
    "            (box1[3] > box2[1] and box1[3] < box2[3])\n",
    "        )\n",
    "        containment_factor = 1.0 if (\n",
    "            contained_horizontally and contained_vertically) else 0.0\n",
    "\n",
    "        # Calculate occlusion score (weighted combination of factors)\n",
    "        occlusion_score = (\n",
    "            0.4 * overlap_factor +\n",
    "            0.2 * size_factor +\n",
    "            0.2 * position_factor +\n",
    "            0.2 * containment_factor\n",
    "        )\n",
    "\n",
    "        # Determine if occluded based on score threshold\n",
    "        is_occluded = occlusion_score > 0.5\n",
    "\n",
    "        return is_occluded, occlusion_score\n",
    "\n",
    "    def calculate_similarity_matrix(self, current_features, current_boxes, tracked_features, tracked_boxes):\n",
    "        \"\"\"Calculate similarity matrix combining appearance, position, and motion\"\"\"\n",
    "        n_detections = len(current_features)\n",
    "        n_tracks = len(tracked_features)\n",
    "\n",
    "        if n_detections == 0 or n_tracks == 0:\n",
    "            return np.array([])\n",
    "\n",
    "        # Calculate appearance similarity\n",
    "        appearance_sim = 1 - distance.cdist(\n",
    "            np.array([f.flatten() for f in current_features]),\n",
    "            np.array([f.flatten() for f in tracked_features]),\n",
    "            metric='cosine'\n",
    "        )\n",
    "\n",
    "        # Calculate position similarity using IoU\n",
    "        position_sim = np.zeros((n_detections, n_tracks))\n",
    "        for i, box1 in enumerate(current_boxes):\n",
    "            for j, box2 in enumerate(tracked_boxes):\n",
    "                position_sim[i, j] = self.calculate_iou(box1, box2)\n",
    "\n",
    "        # Calculate velocities for tracked objects\n",
    "        tracked_velocities = []\n",
    "        for track_id in list(self.active_tracks.keys())[:n_tracks]:\n",
    "            if 'previous_box' in self.active_tracks[track_id]:\n",
    "                velocity = self.calculate_velocity(\n",
    "                    self.active_tracks[track_id]['box'],\n",
    "                    self.active_tracks[track_id]['previous_box']\n",
    "                )\n",
    "            else:\n",
    "                velocity = [0, 0]  # No velocity for new tracks\n",
    "            tracked_velocities.append(velocity)\n",
    "\n",
    "        # Calculate motion similarity\n",
    "        motion_sim = self.calculate_motion_similarity(\n",
    "            current_boxes, tracked_boxes, tracked_velocities)\n",
    "\n",
    "        # Combine all similarities\n",
    "        similarity_matrix = (\n",
    "            self.feature_weight * appearance_sim +\n",
    "            self.position_weight * position_sim +\n",
    "            self.motion_weight * motion_sim\n",
    "        )\n",
    "\n",
    "        return similarity_matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_iou(box1, box2):\n",
    "        \"\"\"Calculate IoU between two boxes\"\"\"\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "\n",
    "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        union = area1 + area2 - intersection\n",
    "\n",
    "        return intersection / (union + 1e-6)\n",
    "\n",
    "    def update_feature_history(self, track_id, features):\n",
    "        \"\"\"Maintain rolling window of recent features\"\"\"\n",
    "        self.appearance_history[track_id].append(features)\n",
    "        if len(self.appearance_history[track_id]) > self.max_history_length:\n",
    "            self.appearance_history[track_id].pop(0)\n",
    "\n",
    "        # Update feature representation using exponential moving average\n",
    "        if track_id in self.person_features:\n",
    "            alpha = 0.7  # Weight for historical features\n",
    "            current_features = self.person_features[track_id]\n",
    "            updated_features = alpha * \\\n",
    "                current_features + (1 - alpha) * features\n",
    "            self.person_features[track_id] = updated_features\n",
    "        else:\n",
    "            self.person_features[track_id] = features\n",
    "\n",
    "    def recover_lost_tracklet(self, features, current_box, frame_time):\n",
    "        \"\"\"Attempt to recover lost tracks\"\"\"\n",
    "        best_match_id = None\n",
    "        best_match_score = 0\n",
    "\n",
    "        # Check recently lost tracks\n",
    "        lost_tracks_to_remove = []\n",
    "        for lost_id, lost_info in self.lost_tracks.items():\n",
    "            # Skip if lost track is too old\n",
    "            if frame_time - lost_info['last_seen'] > self.max_lost_age:\n",
    "                lost_tracks_to_remove.append(lost_id)\n",
    "                continue\n",
    "\n",
    "            # Calculate appearance similarity\n",
    "            lost_features = lost_info['features']\n",
    "            appearance_sim = 1 - \\\n",
    "                distance.cosine(features.flatten(), lost_features.flatten())\n",
    "\n",
    "            # Calculate position similarity based on predicted movement\n",
    "            predicted_box = self.predict_next_position(\n",
    "                lost_info['box'],\n",
    "                lost_info['velocity']\n",
    "            )\n",
    "            position_sim = self.calculate_iou(current_box, predicted_box)\n",
    "\n",
    "            # Combine similarities\n",
    "            match_score = (\n",
    "                self.feature_weight * appearance_sim +\n",
    "                self.position_weight * position_sim\n",
    "            )\n",
    "\n",
    "            # Check temporal consistency\n",
    "            if match_score > 0.6 and match_score > best_match_score:\n",
    "                best_match_score = match_score\n",
    "                best_match_id = lost_id\n",
    "\n",
    "        # Clean up old lost tracks\n",
    "        for lost_id in lost_tracks_to_remove:\n",
    "            del self.lost_tracks[lost_id]\n",
    "\n",
    "        return best_match_id if best_match_score > 0.6 else None\n",
    "\n",
    "    def update_tracks(self, frame, detections, frame_time):\n",
    "        \"\"\"Update tracks with new detections\"\"\"\n",
    "        current_boxes = []\n",
    "        current_features = []\n",
    "\n",
    "        # Process new detections\n",
    "        for box, conf in detections:\n",
    "            if conf < self.min_detection_confidence:\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            person_crop = frame[y1:y2, x1:x2]\n",
    "            if person_crop.size == 0:\n",
    "                continue\n",
    "\n",
    "            features = self.extract_features(person_crop)\n",
    "            if features is not None:\n",
    "                current_boxes.append([x1, y1, x2, y2])\n",
    "                current_features.append(features)\n",
    "\n",
    "        # Get tracked boxes and features\n",
    "        tracked_boxes = []\n",
    "        tracked_features = []\n",
    "        tracked_ids = []\n",
    "\n",
    "        for track_id, track_info in self.active_tracks.items():\n",
    "            tracked_boxes.append(track_info['box'])\n",
    "            tracked_features.append(track_info['features'])\n",
    "            tracked_ids.append(track_id)\n",
    "\n",
    "        # Calculate similarity matrix\n",
    "        similarity_matrix = self.calculate_similarity_matrix(\n",
    "            current_features, current_boxes,\n",
    "            tracked_features, tracked_boxes\n",
    "        )\n",
    "\n",
    "        # Perform matching\n",
    "        matched_indices = []\n",
    "        if similarity_matrix.size > 0:\n",
    "            row_ind, col_ind = linear_sum_assignment(-similarity_matrix)\n",
    "            matched_indices = list(zip(row_ind, col_ind))\n",
    "\n",
    "        # Process matches\n",
    "        unmatched_detections = []\n",
    "        matched_track_ids = set()\n",
    "\n",
    "        for detection_idx, track_idx in matched_indices:\n",
    "            similarity = similarity_matrix[detection_idx, track_idx]\n",
    "            if similarity >= self.similarity_threshold:\n",
    "                track_id = tracked_ids[track_idx]\n",
    "                matched_track_ids.add(track_id)\n",
    "\n",
    "                # Update track\n",
    "                self.active_tracks[track_id].update({\n",
    "                    'previous_box': self.active_tracks[track_id]['box'],\n",
    "                    'box': current_boxes[detection_idx],\n",
    "                    'features': current_features[detection_idx],\n",
    "                    'last_seen': frame_time,\n",
    "                    'disappeared': 0\n",
    "                })\n",
    "\n",
    "                # Update timestamps\n",
    "                self.person_timestamps[track_id]['last_appearance'] = frame_time\n",
    "\n",
    "                # Save person image\n",
    "                self.save_person_image(track_id,\n",
    "                                       frame[current_boxes[detection_idx][1]:current_boxes[detection_idx][3],\n",
    "                                             current_boxes[detection_idx][0]:current_boxes[detection_idx][2]])\n",
    "            else:\n",
    "                unmatched_detections.append(detection_idx)\n",
    "\n",
    "        # Add unmatched detections as new tracks\n",
    "        for detection_idx in range(len(current_features)):\n",
    "            if not any(detection_idx == m[0] for m in matched_indices):\n",
    "                new_id = self.next_id\n",
    "                self.next_id += 1\n",
    "\n",
    "                self.active_tracks[new_id] = {\n",
    "                    'state': TrackingState.TENTATIVE,\n",
    "                    'occlusion_counter': 0,\n",
    "                    'box': current_boxes[detection_idx],\n",
    "                    'features': current_features[detection_idx],\n",
    "                    'last_seen': frame_time,\n",
    "                    'disappeared': 0,\n",
    "                    'velocity': [0, 0]  # Initialize velocity for new tracks\n",
    "                }\n",
    "\n",
    "                self.person_features[new_id] = [\n",
    "                    current_features[detection_idx]]\n",
    "                self.person_timestamps[new_id] = {\n",
    "                    'first_appearance': frame_time,\n",
    "                    'last_appearance': frame_time\n",
    "                }\n",
    "\n",
    "                # Save person image\n",
    "                self.save_person_image(new_id,\n",
    "                                       frame[current_boxes[detection_idx][1]:current_boxes[detection_idx][3],\n",
    "                                             current_boxes[detection_idx][0]:current_boxes[detection_idx][2]])\n",
    "\n",
    "        # Update disappeared tracks\n",
    "        current_time = frame_time\n",
    "        tracks_to_remove = []\n",
    "\n",
    "        for track_id in self.active_tracks:\n",
    "            if track_id not in matched_track_ids:\n",
    "                self.active_tracks[track_id]['disappeared'] += 1\n",
    "                if self.active_tracks[track_id]['disappeared'] > self.max_disappeared:\n",
    "                    tracks_to_remove.append(track_id)\n",
    "\n",
    "        # Remove old tracks\n",
    "        for track_id in tracks_to_remove:\n",
    "            del self.active_tracks[track_id]\n",
    "\n",
    "    def save_person_image(self, person_id, frame):\n",
    "        \"\"\"Save person image to output directory\"\"\"\n",
    "        person_dir = os.path.join(self.output_dir, f\"person_{person_id}\")\n",
    "        os.makedirs(person_dir, exist_ok=True)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "        cv2.imwrite(os.path.join(person_dir, f\"{timestamp}.jpg\"), frame)\n",
    "\n",
    "    def process_video(self):\n",
    "        frame_count = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame_time = frame_count / self.fps\n",
    "            frame_count += 1\n",
    "\n",
    "            # Detect persons using YOLO\n",
    "            results = self.detector(frame, classes=[0])  # class 0 is person\n",
    "\n",
    "            # Process detections\n",
    "            detections = []\n",
    "            for result in results:\n",
    "                boxes = result.boxes.cpu().numpy()\n",
    "                for box in boxes:\n",
    "                    detections.append((box.xyxy[0], box.conf[0]))\n",
    "\n",
    "            # Update tracking\n",
    "            self.update_tracks(frame, detections, frame_time)\n",
    "\n",
    "            # Visualize results\n",
    "            for track_id, track_info in self.active_tracks.items():\n",
    "                box = track_info['box']\n",
    "                cv2.rectangle(frame, (int(box[0]), int(box[1])),\n",
    "                              (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"ID: {track_id}\",\n",
    "                            (int(box[0]), int(box[1])-10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            # Display frame\n",
    "            cv2.imshow('Tracking', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        return self.generate_report()\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate tracking report\"\"\"\n",
    "        report = {\n",
    "            'total_unique_persons': self.next_id,\n",
    "            'person_details': {}\n",
    "        }\n",
    "\n",
    "        for person_id in self.person_timestamps.keys():\n",
    "            report['person_details'][person_id] = {\n",
    "                'first_appearance': self.person_timestamps[person_id]['first_appearance'],\n",
    "                'last_appearance': self.person_timestamps[person_id]['last_appearance'],\n",
    "                'duration': self.person_timestamps[person_id]['last_appearance'] -\n",
    "                self.person_timestamps[person_id]['first_appearance'],\n",
    "                'image_path': os.path.join(self.output_dir, f\"person_{person_id}\")\n",
    "            }\n",
    "\n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded imagenet pretrained weights from \"C:\\Users\\mc1159/.cache\\torch\\checkpoints\\osnet_x1_0_imagenet.pth\"\n",
      "\n",
      "0: 384x640 8 persons, 138.6ms\n",
      "Speed: 10.5ms preprocess, 138.6ms inference, 246.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 73.1ms\n",
      "Speed: 6.4ms preprocess, 73.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 67.6ms\n",
      "Speed: 4.0ms preprocess, 67.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 69.9ms\n",
      "Speed: 3.0ms preprocess, 69.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 71.3ms\n",
      "Speed: 2.0ms preprocess, 71.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 69.4ms\n",
      "Speed: 2.5ms preprocess, 69.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 69.8ms\n",
      "Speed: 2.2ms preprocess, 69.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 69.2ms\n",
      "Speed: 4.0ms preprocess, 69.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 71.0ms\n",
      "Speed: 2.0ms preprocess, 71.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 69.2ms\n",
      "Speed: 4.0ms preprocess, 69.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 68.7ms\n",
      "Speed: 3.0ms preprocess, 68.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 67.5ms\n",
      "Speed: 3.0ms preprocess, 67.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 68.5ms\n",
      "Speed: 3.0ms preprocess, 68.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 67.8ms\n",
      "Speed: 3.0ms preprocess, 67.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 68.4ms\n",
      "Speed: 3.0ms preprocess, 68.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 68.9ms\n",
      "Speed: 3.0ms preprocess, 68.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 68.6ms\n",
      "Speed: 3.0ms preprocess, 68.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 69.3ms\n",
      "Speed: 4.0ms preprocess, 69.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 69.0ms\n",
      "Speed: 4.0ms preprocess, 69.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 69.4ms\n",
      "Speed: 3.0ms preprocess, 69.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 70.3ms\n",
      "Speed: 3.0ms preprocess, 70.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 68.4ms\n",
      "Speed: 3.0ms preprocess, 68.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 67.5ms\n",
      "Speed: 3.0ms preprocess, 67.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 68.1ms\n",
      "Speed: 2.0ms preprocess, 68.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 69.5ms\n",
      "Speed: 3.0ms preprocess, 69.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 67.6ms\n",
      "Speed: 3.0ms preprocess, 67.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 68.2ms\n",
      "Speed: 3.0ms preprocess, 68.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 69.0ms\n",
      "Speed: 3.0ms preprocess, 69.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 68.8ms\n",
      "Speed: 3.4ms preprocess, 68.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 68.6ms\n",
      "Speed: 3.0ms preprocess, 68.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 70.1ms\n",
      "Speed: 2.0ms preprocess, 70.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.3ms\n",
      "Speed: 3.0ms preprocess, 69.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 70.1ms\n",
      "Speed: 3.0ms preprocess, 70.1ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 73.4ms\n",
      "Speed: 3.0ms preprocess, 73.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 67.4ms\n",
      "Speed: 4.0ms preprocess, 67.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.1ms\n",
      "Speed: 2.0ms preprocess, 69.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.4ms\n",
      "Speed: 3.0ms preprocess, 69.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 70.1ms\n",
      "Speed: 3.0ms preprocess, 70.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.3ms\n",
      "Speed: 3.0ms preprocess, 70.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 68.5ms\n",
      "Speed: 3.0ms preprocess, 68.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.2ms\n",
      "Speed: 4.0ms preprocess, 68.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 67.4ms\n",
      "Speed: 3.0ms preprocess, 67.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.5ms\n",
      "Speed: 3.0ms preprocess, 69.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 70.0ms\n",
      "Speed: 3.0ms preprocess, 70.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 75.3ms\n",
      "Speed: 4.0ms preprocess, 75.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.6ms\n",
      "Speed: 3.5ms preprocess, 69.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 68.1ms\n",
      "Speed: 3.0ms preprocess, 68.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 70.4ms\n",
      "Speed: 3.0ms preprocess, 70.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 67.4ms\n",
      "Speed: 3.0ms preprocess, 67.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 67.2ms\n",
      "Speed: 3.0ms preprocess, 67.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 69.4ms\n",
      "Speed: 3.0ms preprocess, 69.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 69.6ms\n",
      "Speed: 3.0ms preprocess, 69.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 67.5ms\n",
      "Speed: 4.0ms preprocess, 67.5ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.5ms\n",
      "Speed: 3.1ms preprocess, 70.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.2ms\n",
      "Speed: 2.0ms preprocess, 70.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 69.7ms\n",
      "Speed: 3.0ms preprocess, 69.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 68.4ms\n",
      "Speed: 3.0ms preprocess, 68.4ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 70.5ms\n",
      "Speed: 2.0ms preprocess, 70.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 69.4ms\n",
      "Speed: 3.0ms preprocess, 69.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 88.8ms\n",
      "Speed: 3.0ms preprocess, 88.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 67.7ms\n",
      "Speed: 3.0ms preprocess, 67.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 69.4ms\n",
      "Speed: 3.0ms preprocess, 69.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 69.3ms\n",
      "Speed: 6.2ms preprocess, 69.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 71.2ms\n",
      "Speed: 4.0ms preprocess, 71.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 68.4ms\n",
      "Speed: 3.9ms preprocess, 68.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.7ms\n",
      "Speed: 3.0ms preprocess, 68.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.5ms\n",
      "Speed: 2.0ms preprocess, 69.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 68.8ms\n",
      "Speed: 2.0ms preprocess, 68.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 68.4ms\n",
      "Speed: 4.0ms preprocess, 68.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.6ms\n",
      "Speed: 3.0ms preprocess, 69.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 70.0ms\n",
      "Speed: 3.0ms preprocess, 70.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.6ms\n",
      "Speed: 2.6ms preprocess, 69.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.3ms\n",
      "Speed: 2.0ms preprocess, 70.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.0ms\n",
      "Speed: 4.0ms preprocess, 70.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.0ms\n",
      "Speed: 3.0ms preprocess, 70.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 69.6ms\n",
      "Speed: 3.0ms preprocess, 69.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.4ms\n",
      "Speed: 3.0ms preprocess, 70.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.6ms\n",
      "Speed: 3.0ms preprocess, 69.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 71.3ms\n",
      "Speed: 2.0ms preprocess, 71.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 67.8ms\n",
      "Speed: 3.0ms preprocess, 67.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.8ms\n",
      "Speed: 3.0ms preprocess, 69.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 71.8ms\n",
      "Speed: 5.0ms preprocess, 71.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.5ms\n",
      "Speed: 3.6ms preprocess, 69.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 70.0ms\n",
      "Speed: 3.0ms preprocess, 70.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.5ms\n",
      "Speed: 2.0ms preprocess, 69.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.5ms\n",
      "Speed: 4.0ms preprocess, 70.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 70.5ms\n",
      "Speed: 3.3ms preprocess, 70.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.2ms\n",
      "Speed: 3.0ms preprocess, 69.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.6ms\n",
      "Speed: 3.0ms preprocess, 69.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 70.8ms\n",
      "Speed: 3.0ms preprocess, 70.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 70.6ms\n",
      "Speed: 3.7ms preprocess, 70.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 70.1ms\n",
      "Speed: 4.0ms preprocess, 70.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 70.3ms\n",
      "Speed: 3.0ms preprocess, 70.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 69.4ms\n",
      "Speed: 3.0ms preprocess, 69.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 68.7ms\n",
      "Speed: 5.0ms preprocess, 68.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.4ms\n",
      "Speed: 2.0ms preprocess, 69.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 71.3ms\n",
      "Speed: 2.0ms preprocess, 71.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.0ms\n",
      "Speed: 9.6ms preprocess, 69.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 71.0ms\n",
      "Speed: 4.7ms preprocess, 71.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.4ms\n",
      "Speed: 3.0ms preprocess, 70.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 68.2ms\n",
      "Speed: 4.0ms preprocess, 68.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.9ms\n",
      "Speed: 3.0ms preprocess, 69.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 69.4ms\n",
      "Speed: 4.2ms preprocess, 69.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 69.1ms\n",
      "Speed: 3.0ms preprocess, 69.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.7ms\n",
      "Speed: 3.0ms preprocess, 68.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 70.6ms\n",
      "Speed: 3.0ms preprocess, 70.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 68.6ms\n",
      "Speed: 3.0ms preprocess, 68.6ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 70.5ms\n",
      "Speed: 3.0ms preprocess, 70.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 66.8ms\n",
      "Speed: 3.0ms preprocess, 66.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 69.3ms\n",
      "Speed: 3.0ms preprocess, 69.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.3ms\n",
      "Speed: 3.0ms preprocess, 69.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 68.9ms\n",
      "Speed: 3.1ms preprocess, 68.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 67.6ms\n",
      "Speed: 3.0ms preprocess, 67.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.3ms\n",
      "Speed: 3.0ms preprocess, 69.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 67.5ms\n",
      "Speed: 3.0ms preprocess, 67.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 68.8ms\n",
      "Speed: 3.0ms preprocess, 68.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.3ms\n",
      "Speed: 2.0ms preprocess, 68.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 70.7ms\n",
      "Speed: 2.0ms preprocess, 70.7ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 68.9ms\n",
      "Speed: 3.0ms preprocess, 68.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 67.9ms\n",
      "Speed: 3.0ms preprocess, 67.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 70.0ms\n",
      "Speed: 3.0ms preprocess, 70.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 68.8ms\n",
      "Speed: 3.0ms preprocess, 68.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 68.2ms\n",
      "Speed: 3.0ms preprocess, 68.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 67.4ms\n",
      "Speed: 2.0ms preprocess, 67.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 69.4ms\n",
      "Speed: 3.0ms preprocess, 69.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 68.6ms\n",
      "Speed: 3.0ms preprocess, 68.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 69.1ms\n",
      "Speed: 3.0ms preprocess, 69.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 67.0ms\n",
      "Speed: 3.0ms preprocess, 67.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 69.3ms\n",
      "Speed: 2.0ms preprocess, 69.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 69.3ms\n",
      "Speed: 2.0ms preprocess, 69.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 69.4ms\n",
      "Speed: 2.0ms preprocess, 69.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 73.7ms\n",
      "Speed: 2.0ms preprocess, 73.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 72.3ms\n",
      "Speed: 2.0ms preprocess, 72.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 74.8ms\n",
      "Speed: 3.0ms preprocess, 74.8ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 70.9ms\n",
      "Speed: 3.6ms preprocess, 70.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 72.2ms\n",
      "Speed: 2.0ms preprocess, 72.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 67.4ms\n",
      "Speed: 3.0ms preprocess, 67.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 69.3ms\n",
      "Speed: 3.7ms preprocess, 69.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 66.3ms\n",
      "Speed: 3.0ms preprocess, 66.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 68.6ms\n",
      "Speed: 3.0ms preprocess, 68.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 76.1ms\n",
      "Speed: 3.0ms preprocess, 76.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 71.3ms\n",
      "Speed: 3.0ms preprocess, 71.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 72.3ms\n",
      "Speed: 3.0ms preprocess, 72.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 70.8ms\n",
      "Speed: 4.0ms preprocess, 70.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 72.9ms\n",
      "Speed: 3.0ms preprocess, 72.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.8ms\n",
      "Speed: 2.0ms preprocess, 69.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 69.3ms\n",
      "Speed: 3.0ms preprocess, 69.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 68.8ms\n",
      "Speed: 3.0ms preprocess, 68.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 72.3ms\n",
      "Speed: 3.0ms preprocess, 72.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 67.3ms\n",
      "Speed: 3.0ms preprocess, 67.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 70.3ms\n",
      "Speed: 3.0ms preprocess, 70.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 66.7ms\n",
      "Speed: 4.0ms preprocess, 66.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.8ms\n",
      "Speed: 2.0ms preprocess, 69.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 70.3ms\n",
      "Speed: 3.0ms preprocess, 70.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 69.8ms\n",
      "Speed: 3.0ms preprocess, 69.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 70.3ms\n",
      "Speed: 3.0ms preprocess, 70.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 69.5ms\n",
      "Speed: 3.0ms preprocess, 69.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 74.3ms\n",
      "Speed: 3.0ms preprocess, 74.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 70.8ms\n",
      "Speed: 3.0ms preprocess, 70.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 69.2ms\n",
      "Speed: 2.0ms preprocess, 69.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 67.3ms\n",
      "Speed: 4.2ms preprocess, 67.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 68.8ms\n",
      "Speed: 3.0ms preprocess, 68.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 71.6ms\n",
      "Speed: 2.0ms preprocess, 71.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.3ms\n",
      "Speed: 4.0ms preprocess, 69.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.9ms\n",
      "Speed: 3.0ms preprocess, 68.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 68.4ms\n",
      "Speed: 3.0ms preprocess, 68.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 68.8ms\n",
      "Speed: 3.0ms preprocess, 68.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 71.5ms\n",
      "Speed: 3.0ms preprocess, 71.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 68.3ms\n",
      "Speed: 4.0ms preprocess, 68.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 71.3ms\n",
      "Speed: 3.0ms preprocess, 71.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 69.8ms\n",
      "Speed: 4.0ms preprocess, 69.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 67.3ms\n",
      "Speed: 2.0ms preprocess, 67.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.8ms\n",
      "Speed: 3.0ms preprocess, 69.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.0ms\n",
      "Speed: 3.0ms preprocess, 68.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 69.3ms\n",
      "Speed: 3.0ms preprocess, 69.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.3ms\n",
      "Speed: 2.0ms preprocess, 69.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 66.2ms\n",
      "Speed: 3.0ms preprocess, 66.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 66.3ms\n",
      "Speed: 3.0ms preprocess, 66.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 70.9ms\n",
      "Speed: 3.0ms preprocess, 70.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 68.7ms\n",
      "Speed: 2.0ms preprocess, 68.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 61.1ms\n",
      "Speed: 3.0ms preprocess, 61.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 67.4ms\n",
      "Speed: 3.0ms preprocess, 67.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 69.8ms\n",
      "Speed: 3.7ms preprocess, 69.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 67.3ms\n",
      "Speed: 3.0ms preprocess, 67.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 70.3ms\n",
      "Speed: 3.0ms preprocess, 70.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.4ms\n",
      "Speed: 3.0ms preprocess, 69.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 69.0ms\n",
      "Speed: 3.0ms preprocess, 69.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.3ms\n",
      "Speed: 3.0ms preprocess, 69.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 70.7ms\n",
      "Speed: 4.0ms preprocess, 70.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 69.3ms\n",
      "Speed: 2.0ms preprocess, 69.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 68.3ms\n",
      "Speed: 3.0ms preprocess, 68.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.8ms\n",
      "Speed: 2.0ms preprocess, 69.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.2ms\n",
      "Speed: 2.0ms preprocess, 69.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.3ms\n",
      "Speed: 2.0ms preprocess, 68.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 68.3ms\n",
      "Speed: 4.0ms preprocess, 68.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.3ms\n",
      "Speed: 3.0ms preprocess, 69.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.8ms\n",
      "Speed: 3.0ms preprocess, 69.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 80.3ms\n",
      "Speed: 4.0ms preprocess, 80.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 69.7ms\n",
      "Speed: 3.0ms preprocess, 69.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.8ms\n",
      "Speed: 4.0ms preprocess, 69.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.9ms\n",
      "Speed: 3.1ms preprocess, 68.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 71.1ms\n",
      "Speed: 3.0ms preprocess, 71.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 70.2ms\n",
      "Speed: 3.0ms preprocess, 70.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 71.3ms\n",
      "Speed: 3.0ms preprocess, 71.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 70.6ms\n",
      "Speed: 3.0ms preprocess, 70.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 72.1ms\n",
      "Speed: 2.0ms preprocess, 72.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 70.8ms\n",
      "Speed: 3.0ms preprocess, 70.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.9ms\n",
      "Speed: 3.0ms preprocess, 69.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.9ms\n",
      "Speed: 2.0ms preprocess, 68.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 70.5ms\n",
      "Speed: 2.0ms preprocess, 70.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 71.3ms\n",
      "Speed: 3.0ms preprocess, 71.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 71.7ms\n",
      "Speed: 2.0ms preprocess, 71.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 73.3ms\n",
      "Speed: 3.0ms preprocess, 73.3ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.9ms\n",
      "Speed: 3.0ms preprocess, 70.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 73.0ms\n",
      "Speed: 2.0ms preprocess, 73.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.6ms\n",
      "Speed: 3.0ms preprocess, 69.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 71.5ms\n",
      "Speed: 4.0ms preprocess, 71.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 70.3ms\n",
      "Speed: 3.0ms preprocess, 70.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 70.3ms\n",
      "Speed: 3.0ms preprocess, 70.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 69.6ms\n",
      "Speed: 2.0ms preprocess, 69.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 69.4ms\n",
      "Speed: 2.0ms preprocess, 69.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 71.3ms\n",
      "Speed: 3.0ms preprocess, 71.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.8ms\n",
      "Speed: 4.0ms preprocess, 70.8ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 75.8ms\n",
      "Speed: 3.0ms preprocess, 75.8ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.5ms\n",
      "Speed: 3.0ms preprocess, 69.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 70.1ms\n",
      "Speed: 4.0ms preprocess, 70.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 69.8ms\n",
      "Speed: 3.5ms preprocess, 69.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 71.0ms\n",
      "Speed: 2.0ms preprocess, 71.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 71.4ms\n",
      "Speed: 2.7ms preprocess, 71.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 70.1ms\n",
      "Speed: 2.7ms preprocess, 70.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 70.6ms\n",
      "Speed: 2.0ms preprocess, 70.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.1ms\n",
      "Speed: 2.2ms preprocess, 69.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.6ms\n",
      "Speed: 3.7ms preprocess, 70.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.2ms\n",
      "Speed: 3.0ms preprocess, 70.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 78.1ms\n",
      "Speed: 3.8ms preprocess, 78.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 72.5ms\n",
      "Speed: 3.0ms preprocess, 72.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.5ms\n",
      "Speed: 2.0ms preprocess, 69.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 68.1ms\n",
      "Speed: 3.0ms preprocess, 68.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.0ms\n",
      "Speed: 3.9ms preprocess, 70.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.8ms\n",
      "Speed: 3.6ms preprocess, 69.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.4ms\n",
      "Speed: 3.0ms preprocess, 68.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 71.3ms\n",
      "Speed: 2.0ms preprocess, 71.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 69.2ms\n",
      "Speed: 2.0ms preprocess, 69.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 62.9ms\n",
      "Speed: 3.4ms preprocess, 62.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 69.6ms\n",
      "Speed: 3.8ms preprocess, 69.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 68.9ms\n",
      "Speed: 3.0ms preprocess, 68.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 67.6ms\n",
      "Speed: 4.0ms preprocess, 67.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.9ms\n",
      "Speed: 2.0ms preprocess, 70.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 71.3ms\n",
      "Speed: 3.0ms preprocess, 71.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.4ms\n",
      "Speed: 2.0ms preprocess, 70.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 70.2ms\n",
      "Speed: 3.4ms preprocess, 70.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 72.9ms\n",
      "Speed: 2.0ms preprocess, 72.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 70.6ms\n",
      "Speed: 3.0ms preprocess, 70.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 68.8ms\n",
      "Speed: 3.0ms preprocess, 68.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "video_path = video_path  # Replace with your video path\n",
    "tracker = PersonTracker(video_path)\n",
    "report = tracker.process_video()\n",
    "print(f\"Total unique persons detected: {report['total_unique_persons']}\")\n",
    "for person_id, details in report['person_details'].items():\n",
    "    print(f\"\\nPerson ID: {person_id}\")\n",
    "    print(f\"First appearance: {details['first_appearance']:.2f}s\")\n",
    "    print(f\"Last appearance: {details['last_appearance']:.2f}s\")\n",
    "    print(f\"Duration in video: {details['duration']:.2f}s\")\n",
    "    print(f\"Images saved in: {details['image_path']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cctv-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
