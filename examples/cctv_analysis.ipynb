{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCTV Cross-Camera Person Tracking and Analysis\n",
    "# ============================================\n",
    "\n",
    "This notebook implements cross-camera person tracking and re-identification using:\n",
    "\n",
    "- YOLOX for person detection\n",
    "- ByteTracker for single-camera tracking\n",
    "- Deep Person ReID for cross-camera person re-identification\n",
    "- InsightFace for demographic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mc1159\\AppData\\Local\\anaconda3\\envs\\cctv-analysis\\lib\\site-packages\\torchreid\\reid\\metrics\\rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mc1159\\AppData\\Local\\anaconda3\\envs\\cctv-analysis\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import transforms\n",
    "import wget\n",
    "\n",
    "# Deep Person ReID imports\n",
    "import torchreid\n",
    "from torchreid import models\n",
    "from torchreid import utils\n",
    "\n",
    "# Demographic analysis (using InsightFace)\n",
    "from insightface.app import FaceAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# YOLOX weights\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_folder_path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create model folder if it doesn't exist\u001b[39;00m\n\u001b[0;32m      5\u001b[0m Path(model_folder_path)\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# YOLOX weights\n",
    "import torchreid\n",
    "\n",
    "model_folder_path = os.path.join(\"..\", \"models\")\n",
    "\n",
    "\n",
    "# Create model folder if it doesn't exist\n",
    "\n",
    "Path(model_folder_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.chdir(model_folder_path)\n",
    "\n",
    "\n",
    "# Download YOLOX weights (choose one based on your needs)\n",
    "\n",
    "wget.download(\n",
    "\n",
    "    \"https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_s.pth\")\n",
    "\n",
    "\n",
    "wget.download(\n",
    "\n",
    "    \"https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_m.pth\")\n",
    "\n",
    "\n",
    "wget.download(\n",
    "\n",
    "    \"https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_l.pth\")\n",
    "\n",
    "\n",
    "wget.download(\n",
    "\n",
    "    \"https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_x.pth\")\n",
    "\n",
    "\n",
    "# Then download the weights using torchreid's model zoo\n",
    "\n",
    "# OSNet weights\n",
    "\n",
    "torchreid.utils.download_url(\n",
    "\n",
    "    'https://drive.google.com/uc?id=1vduhq5DpN2q1g4fYEZfPI17MJeh9qyrA',\n",
    "\n",
    "    'osnet_x1_0_market_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip.pth'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # YOLOX Config\n",
    "    YOLOX_EXP_FILE = \"yolox_l\"  # or yolox_m, yolox_l, yolox_x\n",
    "    YOLOX_WEIGHTS = \"yolox_l.pth\"\n",
    "    CONFIDENCE_THRESHOLD = 0.5\n",
    "\n",
    "    # ByteTracker Config\n",
    "    TRACK_BUFFER = 30\n",
    "    TRACK_THRESH = 0.5\n",
    "\n",
    "    # ReID Config\n",
    "    REID_MODEL = 'osnet_x1_0'\n",
    "    REID_WEIGHTS = 'osnet_x1_0_market_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip.pth'\n",
    "\n",
    "    # Video Processing\n",
    "    BATCH_SIZE = 4\n",
    "    INPUT_SIZE = (608, 1088)  # (height, width)\n",
    "\n",
    "    # Matching Config\n",
    "    MAX_COSINE_DISTANCE = 0.3\n",
    "    # maximum time difference (in seconds) for matching\n",
    "    MAX_TIME_DIFFERENCE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\cctv-analysis\n"
     ]
    }
   ],
   "source": [
    "# Change the working directory to the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "os.chdir(parent_dir)\n",
    "# Check current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the CCTV footage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cctv-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
