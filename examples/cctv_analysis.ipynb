{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCTV Cross-Camera Person Tracking and Analysis\n",
    "# ============================================\n",
    "\n",
    "This notebook implements cross-camera person tracking and re-identification using:\n",
    "\n",
    "- YOLOX for person detection\n",
    "- ByteTracker for single-camera tracking\n",
    "- Deep Person ReID for cross-camera person re-identification\n",
    "- InsightFace for demographic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mc1159\\AppData\\Local\\anaconda3\\envs\\cctv-analysis\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "from cctv_analysis.matcher import PersonMatcher\n",
    "from cctv_analysis.demographics import DemographicAnalyzer\n",
    "from cctv_analysis.reid import PersonReID\n",
    "from cctv_analysis.detector import PersonDetector\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPU Status Check ===\n",
      "\n",
      "GPU Found: True\n",
      "CUDA Available: False\n",
      "\n",
      "GPU Information:\n",
      "Thu Nov  7 22:44:18 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.03                 Driver Version: 566.03         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA T1000 8GB             WDDM  |   00000000:21:00.0  On |                  N/A |\n",
      "| 33%   36C    P8             N/A /   50W |     862MiB /   8192MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2044    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      2896    C+G   ...228_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A      4744    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A      5992    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A      6164    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A      7132    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A      7312    C+G   ...228_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A      7832    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      7904    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A      9928    C+G   ...Desktop\\app-3.4.8\\GitHubDesktop.exe      N/A      |\n",
      "|    0   N/A  N/A     15764    C+G   C:\\Windows\\System32\\Taskmgr.exe             N/A      |\n",
      "|    0   N/A  N/A     15900    C+G   ...on\\130.0.2849.56\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     17804    C+G   ...on\\130.0.2849.56\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     17924    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "PyTorch CUDA Version: None\n",
      "PyTorch Built with CUDA: False\n",
      "\n",
      "Recommendations to enable GPU:\n",
      "1. CUDA toolkit not found. Please install CUDA toolkit from: https://developer.nvidia.com/cuda-downloads\n",
      "2. PyTorch is not built with CUDA. Please reinstall PyTorch with CUDA support:\n",
      "pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n"
     ]
    }
   ],
   "source": [
    "# In your Jupyter notebook\n",
    "import cctv_analysis.utils.gpu_check\n",
    "status = cctv_analysis.utils.gpu_check.print_gpu_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, using CPU\n",
      "GPU not available, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\GitHub\\cctv-analysis\\src\\cctv_analysis\\detector.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded YOLOX-L model\n",
      "GPU not available, using CPU\n",
      "Successfully loaded pretrained weights from ../models/reid/osnet_x1_0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\GitHub\\cctv-analysis\\src\\cctv_analysis\\reid.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "    device = 'cpu'\n",
    "\n",
    "# Initialize models\n",
    "detector = PersonDetector(\n",
    "    model_path='../models/detector/yolox_l.pth',\n",
    "    model_size='l',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "reid_model = PersonReID(\n",
    "    model_path='../models/reid/osnet_x1_0.pth',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "demographic_analyzer = DemographicAnalyzer(device=device)\n",
    "\n",
    "# Initialize matcher\n",
    "matcher = PersonMatcher(similarity_threshold=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "    device = 'cpu'\n",
    "\n",
    "# Initialize models\n",
    "detector = PersonDetector(\n",
    "    model_path='../models/detector/yolox_l.pth',\n",
    "    model_size='l',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "reid_model = PersonReID(\n",
    "    model_path='../models/reid/osnet_x1_0.pth',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "demographic_analyzer = DemographicAnalyzer(device=device)\n",
    "\n",
    "# Initialize matcher\n",
    "matcher = PersonMatcher(similarity_threshold=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the CCTV footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, camera_id, start_time):\n",
    "    \"\"\"Process video and add detections to matcher\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Process frames with progress bar\n",
    "    for frame_idx in tqdm(range(frame_count), desc=f\"Processing Camera {camera_id}\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Calculate timestamp\n",
    "        timestamp = start_time + pd.Timedelta(seconds=frame_idx/fps)\n",
    "\n",
    "        # Detect persons\n",
    "        detections = detector.detect(frame, conf_thresh=0.5)\n",
    "\n",
    "        for i, det in enumerate(detections):\n",
    "            x1, y1, x2, y2, conf = det\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "\n",
    "            # Extract person crop\n",
    "            person_crop = frame[y1:y2, x1:x2]\n",
    "            if person_crop.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Extract ReID features\n",
    "            features = reid_model.extract_features(person_crop)\n",
    "\n",
    "            # Analyze demographics\n",
    "            demographics = demographic_analyzer.analyze(person_crop)\n",
    "\n",
    "            # Add to matcher\n",
    "            matcher.add_person(\n",
    "                camera_id=camera_id,\n",
    "                person_id=len(matcher.camera1_persons if camera_id ==\n",
    "                              1 else matcher.camera2_persons),\n",
    "                timestamp=timestamp,\n",
    "                features=features,\n",
    "                demographics=demographics[0] if demographics else None\n",
    "            )\n",
    "\n",
    "        # Clear GPU memory periodically\n",
    "        if device == 'cuda' and frame_idx % 100 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process videos\n",
    "video1_path = '../data/videos/video1.mp4'\n",
    "video2_path = '../data/videos/video2.mp4'\n",
    "\n",
    "# Assuming videos start at these times (adjust as needed)\n",
    "video1_start = pd.Timestamp('2024-01-01 09:00:00')\n",
    "video2_start = pd.Timestamp('2024-01-01 09:00:00')\n",
    "\n",
    "# Process both videos\n",
    "process_video(video1_path, camera_id=1, start_time=video1_start)\n",
    "process_video(video2_path, camera_id=2, start_time=video2_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a single frame\n",
    "cap = cv2.VideoCapture('../data/videos/video1.mp4')\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    # Try different confidence thresholds\n",
    "    for conf in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "        detections = detector.detect(frame, conf_thresh=conf)\n",
    "        print(f\"\\nConfidence threshold: {conf}\")\n",
    "        print(f\"Number of detections: {detections}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize matcher with more lenient parameters\n",
    "matcher = PersonMatcher(\n",
    "    similarity_threshold=0.5,  # Lower threshold for more matches\n",
    "    max_time_diff=3600  # Maximum 1 hour time difference\n",
    ")\n",
    "\n",
    "# After processing videos, print detailed statistics\n",
    "matcher.print_matching_stats()\n",
    "\n",
    "# Visualize some example matches\n",
    "matcher.visualize_matches(n_samples=5)\n",
    "\n",
    "# Get matches and analyze results\n",
    "matches = matcher.get_matches()\n",
    "df_matches = pd.DataFrame(matches)\n",
    "\n",
    "if not df_matches.empty:\n",
    "    print(\"\\nMatching Results:\")\n",
    "    print(f\"Total matches found: {len(df_matches)}\")\n",
    "\n",
    "    # Show similarity score distribution\n",
    "    print(\"\\nSimilarity Score Statistics:\")\n",
    "    print(df_matches['similarity_score'].describe())\n",
    "\n",
    "    # Show time difference distribution\n",
    "    print(\"\\nTime Difference Statistics (seconds):\")\n",
    "    print(df_matches['time_difference'].describe())\n",
    "\n",
    "    # Demographics analysis\n",
    "    demographics_df = pd.DataFrame(\n",
    "        [m['demographics'] for m in matches if m['demographics']])\n",
    "    if not demographics_df.empty:\n",
    "        print(\"\\nDemographic breakdown:\")\n",
    "        print(\"\\nGender distribution:\")\n",
    "        print(demographics_df['gender'].value_counts())\n",
    "        print(\"\\nAge group distribution:\")\n",
    "        print(demographics_df['age_group'].value_counts())\n",
    "\n",
    "    # Save detailed results\n",
    "    output_path = '../data/analysis_results.csv'\n",
    "    df_matches.to_csv(output_path, index=False)\n",
    "    print(f\"\\nDetailed results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No matches found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if not df_matches.empty:\n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Plot similarity score distribution\n",
    "    sns.histplot(df_matches['similarity_score'], ax=ax1)\n",
    "    ax1.set_title('Distribution of Similarity Scores')\n",
    "    ax1.set_xlabel('Similarity Score')\n",
    "\n",
    "    # Plot time difference distribution\n",
    "    sns.histplot(df_matches['time_difference'], ax=ax2)\n",
    "    ax2.set_title('Distribution of Time Differences')\n",
    "    ax2.set_xlabel('Time Difference (seconds)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_matches.empty:\n",
    "    output_path = '../data/analysis_results.csv'\n",
    "    df_matches.to_csv(output_path, index=False)\n",
    "    print(f\"Results saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cctv-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
