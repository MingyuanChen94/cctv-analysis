{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCTV Cross-Camera Person Tracking and Analysis\n",
    "# ============================================\n",
    "\n",
    "This notebook implements cross-camera person tracking and re-identification using:\n",
    "\n",
    "- YOLOX for person detection\n",
    "- ByteTracker for single-camera tracking\n",
    "- Deep Person ReID for cross-camera person re-identification\n",
    "- InsightFace for demographic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mc1159\\AppData\\Local\\anaconda3\\envs\\cctv-analysis\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "from cctv_analysis.matcher import PersonMatcher\n",
    "from cctv_analysis.demographics import DemographicAnalyzer\n",
    "from cctv_analysis.reid import PersonReID\n",
    "from cctv_analysis.detector import PersonDetector\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.2+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "CUDA device: NVIDIA T1000 8GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPU Status Check ===\n",
      "\n",
      "GPU Found: True\n",
      "CUDA Available: True\n",
      "\n",
      "GPU Information:\n",
      "Tue Nov 12 15:15:47 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.03                 Driver Version: 566.03         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA T1000 8GB             WDDM  |   00000000:21:00.0  On |                  N/A |\n",
      "| 34%   35C    P8             N/A /   50W |     931MiB /   8192MiB |      6%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A       732    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      2396    C+G   ...on\\130.0.2849.80\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A      5988    C+G   ...Desktop\\app-3.4.8\\GitHubDesktop.exe      N/A      |\n",
      "|    0   N/A  N/A      7672    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A      7932    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A      9112    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     10220    C+G   ...on\\130.0.2849.80\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     10936    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     12292    C+G   ...804_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A     12872    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13744    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     14028    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A     14956    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     17996    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     19288    C+G   ...804_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A     19412    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     19792    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     20416    C+G   ...on\\130.0.2849.80\\msedgewebview2.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "CUDA Version:\n",
      "Cuda compilation tools, release 12.6, V12.6.77\n",
      "\n",
      "PyTorch CUDA Version: 12.1\n",
      "PyTorch Built with CUDA: True\n"
     ]
    }
   ],
   "source": [
    "# In your Jupyter notebook\n",
    "import cctv_analysis.utils.gpu_check\n",
    "status = cctv_analysis.utils.gpu_check.print_gpu_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA T1000 8GB\n",
      "Using GPU: NVIDIA T1000 8GB\n",
      "GPU Memory Available: 8.00 GB\n",
      "Successfully loaded YOLOX-L model\n",
      "Using GPU: NVIDIA T1000 8GB\n",
      "GPU Memory Available: 8.00 GB\n",
      "Successfully loaded pretrained weights from ../models/reid/osnet_x1_0.pth\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "    device = 'cpu'\n",
    "\n",
    "# Initialize models\n",
    "detector = PersonDetector(\n",
    "    model_path='../models/detector/yolox_l.pth',\n",
    "    model_size='l',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "reid_model = PersonReID(\n",
    "    model_path='../models/reid/osnet_x1_0.pth',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "demographic_analyzer = DemographicAnalyzer(device=device)\n",
    "\n",
    "# Initialize matcher\n",
    "matcher = PersonMatcher(similarity_threshold=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA T1000 8GB\n",
      "Using GPU: NVIDIA T1000 8GB\n",
      "GPU Memory Available: 8.00 GB\n",
      "Successfully loaded YOLOX-L model\n",
      "Using GPU: NVIDIA T1000 8GB\n",
      "GPU Memory Available: 8.00 GB\n",
      "Successfully loaded pretrained weights from ../models/reid/osnet_x1_0.pth\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\mc1159/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "    device = 'cpu'\n",
    "\n",
    "# Initialize models\n",
    "detector = PersonDetector(\n",
    "    model_path='../models/detector/yolox_l.pth',\n",
    "    model_size='l',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "reid_model = PersonReID(\n",
    "    model_path='../models/reid/osnet_x1_0.pth',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "demographic_analyzer = DemographicAnalyzer(device=device)\n",
    "\n",
    "# Initialize matcher\n",
    "matcher = PersonMatcher(similarity_threshold=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the CCTV footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, camera_id, start_time):\n",
    "    \"\"\"Process video and add detections to matcher\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Process frames with progress bar\n",
    "    for frame_idx in tqdm(range(frame_count), desc=f\"Processing Camera {camera_id}\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Calculate timestamp\n",
    "        timestamp = start_time + pd.Timedelta(seconds=frame_idx/fps)\n",
    "\n",
    "        # Detect persons\n",
    "        detections = detector.detect(frame, conf_thresh=0.5)\n",
    "\n",
    "        for i, det in enumerate(detections):\n",
    "            x1, y1, x2, y2, conf = det\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "\n",
    "            # Extract person crop\n",
    "            person_crop = frame[y1:y2, x1:x2]\n",
    "            if person_crop.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Extract ReID features\n",
    "            features = reid_model.extract_features(person_crop)\n",
    "\n",
    "            # Analyze demographics\n",
    "            demographics = demographic_analyzer.analyze(person_crop)\n",
    "\n",
    "            # Add to matcher\n",
    "            matcher.add_person(\n",
    "                camera_id=camera_id,\n",
    "                person_id=len(matcher.camera1_persons if camera_id ==\n",
    "                              1 else matcher.camera2_persons),\n",
    "                timestamp=timestamp,\n",
    "                features=features,\n",
    "                demographics=demographics[0] if demographics else None\n",
    "            )\n",
    "\n",
    "        # Clear GPU memory periodically\n",
    "        if device == 'cuda' and frame_idx % 100 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03202398b6f74179b525c38ced038530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Camera 1:   0%|          | 0/43504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d6489c9637497dbde5d33d5a4e816c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Camera 2:   0%|          | 0/43203 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process videos\n",
    "video1_path = '../data/processed_data/D04_20241108.mp4'\n",
    "video2_path = '../data/processed_data/D10_20241108.mp4'\n",
    "\n",
    "# Assuming videos start at these times (adjust as needed)\n",
    "video1_start = pd.Timestamp('2024-01-01 09:00:00')\n",
    "video2_start = pd.Timestamp('2024-01-01 09:00:00')\n",
    "\n",
    "\n",
    "# Process both videos\n",
    "process_video(video1_path, camera_id=1, start_time=video1_start)\n",
    "process_video(video2_path, camera_id=2, start_time=video2_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a single frame\n",
    "cap = cv2.VideoCapture('../data/videos/video1.mp4')\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    # Try different confidence thresholds\n",
    "    for conf in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "        detections = detector.detect(frame, conf_thresh=conf)\n",
    "        print(f\"\\nConfidence threshold: {conf}\")\n",
    "        print(f\"Number of detections: {detections}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matching Statistics:\n",
      "Number of people detected in Camera 1: 0\n",
      "Number of people detected in Camera 2: 0\n",
      "Number of matches found: 0\n",
      "No matches to visualize\n",
      "No matches found\n"
     ]
    }
   ],
   "source": [
    "# Initialize matcher with more lenient parameters\n",
    "matcher = PersonMatcher(\n",
    "    similarity_threshold=0.5,  # Lower threshold for more matches\n",
    "    max_time_diff=3600  # Maximum 1 hour time difference\n",
    ")\n",
    "\n",
    "# After processing videos, print detailed statistics\n",
    "matcher.print_matching_stats()\n",
    "\n",
    "# Visualize some example matches\n",
    "matcher.visualize_matches(n_samples=5)\n",
    "\n",
    "# Get matches and analyze results\n",
    "matches = matcher.get_matches()\n",
    "df_matches = pd.DataFrame(matches)\n",
    "\n",
    "if not df_matches.empty:\n",
    "    print(\"\\nMatching Results:\")\n",
    "    print(f\"Total matches found: {len(df_matches)}\")\n",
    "\n",
    "    # Show similarity score distribution\n",
    "    print(\"\\nSimilarity Score Statistics:\")\n",
    "    print(df_matches['similarity_score'].describe())\n",
    "\n",
    "    # Show time difference distribution\n",
    "    print(\"\\nTime Difference Statistics (seconds):\")\n",
    "    print(df_matches['time_difference'].describe())\n",
    "\n",
    "    # Demographics analysis\n",
    "    demographics_df = pd.DataFrame(\n",
    "        [m['demographics'] for m in matches if m['demographics']])\n",
    "    if not demographics_df.empty:\n",
    "        print(\"\\nDemographic breakdown:\")\n",
    "        print(\"\\nGender distribution:\")\n",
    "        print(demographics_df['gender'].value_counts())\n",
    "        print(\"\\nAge group distribution:\")\n",
    "        print(demographics_df['age_group'].value_counts())\n",
    "\n",
    "    # Save detailed results\n",
    "    output_path = '../data/analysis_results.csv'\n",
    "    df_matches.to_csv(output_path, index=False)\n",
    "    print(f\"\\nDetailed results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No matches found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if not df_matches.empty:\n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Plot similarity score distribution\n",
    "    sns.histplot(df_matches['similarity_score'], ax=ax1)\n",
    "    ax1.set_title('Distribution of Similarity Scores')\n",
    "    ax1.set_xlabel('Similarity Score')\n",
    "\n",
    "    # Plot time difference distribution\n",
    "    sns.histplot(df_matches['time_difference'], ax=ax2)\n",
    "    ax2.set_title('Distribution of Time Differences')\n",
    "    ax2.set_xlabel('Time Difference (seconds)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_matches.empty:\n",
    "    output_path = '../data/analysis_results.csv'\n",
    "    df_matches.to_csv(output_path, index=False)\n",
    "    print(f\"Results saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cctv-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
