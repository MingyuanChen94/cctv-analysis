{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the working directory\n",
    "working_directory = os.path.join(os.path.expanduser(\"~\"), \"Library\", \"CloudStorage\", \n",
    "                              \"OneDrive-UniversityofExeter\", \"Documents\", \"VISIONARY\", \n",
    "                              \"Durham Experiment\", \"processed_data_3\")\n",
    "os.chdir(working_directory)\n",
    "\n",
    "# Verify the current working directory\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Get the .mp4 files in the folder\n",
    "mp4_files = list(Path(working_directory).glob(\"*.mp4\"))\n",
    "# Print the .mp4 files without showing the parent directories\n",
    "print([file.name for file in mp4_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the files for Camera_1 and Camera_2\n",
    "camera_1_files = [file for file in mp4_files if file.name.startswith(\"Camera_1_\")]\n",
    "camera_2_files = [file for file in mp4_files if file.name.startswith(\"Camera_2_\")]\n",
    "\n",
    "# Sort the files by date extracted from the filename\n",
    "camera_1_files_sorted = sorted(camera_1_files, key=lambda x: x.stem.split('_')[-1])\n",
    "camera_2_files_sorted = sorted(camera_2_files, key=lambda x: x.stem.split('_')[-1])\n",
    "\n",
    "print(\"Camera 1 files sorted by date:\", [file.name for file in camera_1_files_sorted])\n",
    "print(\"Camera 2 files sorted by date:\", [file.name for file in camera_2_files_sorted])\n",
    "\n",
    "del mp4_files, camera_1_files, camera_2_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def draw_door_area(video_path, save_path):\n",
    "    # Read the first frame of the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    # Create a copy of the original frame\n",
    "    original_frame = frame.copy()\n",
    "    drawing_frame = frame.copy()\n",
    "    \n",
    "    # Store the coordinates of the rectangle\n",
    "    door_coords = []\n",
    "    \n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        nonlocal drawing_frame\n",
    "        \n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            # Reset if we already have 2 points\n",
    "            if len(door_coords) == 2:\n",
    "                door_coords.clear()\n",
    "                drawing_frame = original_frame.copy()\n",
    "            \n",
    "            door_coords.append((x, y))\n",
    "            # Draw point for visual feedback\n",
    "            cv2.circle(drawing_frame, (x, y), 3, (0, 255, 0), -1)\n",
    "            \n",
    "            if len(door_coords) == 2:\n",
    "                # Draw rectangle using the two points\n",
    "                cv2.rectangle(drawing_frame, door_coords[0], door_coords[1], (0, 255, 0), 2)\n",
    "                # Add instruction text\n",
    "                cv2.putText(drawing_frame, \"Press 'r' to redraw, Enter to confirm\", \n",
    "                          (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.imshow('Frame', drawing_frame)\n",
    "\n",
    "    # Create window and set mouse callback\n",
    "    cv2.imshow('Frame', drawing_frame)\n",
    "    cv2.setMouseCallback('Frame', mouse_callback)\n",
    "    \n",
    "    # Instructions\n",
    "    print(\"Instructions:\")\n",
    "    print(\"1. Click two points to draw a rectangle\")\n",
    "    print(\"2. Press 'r' to redraw if needed\")\n",
    "    print(\"3. Press Enter to confirm and save\")\n",
    "    print(\"4. Press 'q' to quit without saving\")\n",
    "    \n",
    "    while True:\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        # Press 'r' to reset\n",
    "        if key == ord('r'):\n",
    "            door_coords.clear()\n",
    "            drawing_frame = original_frame.copy()\n",
    "            cv2.imshow('Frame', drawing_frame)\n",
    "        \n",
    "        # Press Enter to confirm\n",
    "        elif key == 13:  # Enter key\n",
    "            if len(door_coords) == 2:\n",
    "                # Ensure coordinates are in top-left, bottom-right order\n",
    "                x1, y1 = min(door_coords[0][0], door_coords[1][0]), min(door_coords[0][1], door_coords[1][1])\n",
    "                x2, y2 = max(door_coords[0][0], door_coords[1][0]), max(door_coords[0][1], door_coords[1][1])\n",
    "                \n",
    "                coordinates = {\n",
    "                    'top_left': {'x': x1, 'y': y1},\n",
    "                    'bottom_right': {'x': x2, 'y': y2}\n",
    "                }\n",
    "                with open(save_path, 'w') as f:\n",
    "                    json.dump(coordinates, f)\n",
    "                print(f\"\\nDoor coordinates saved to {save_path}:\")\n",
    "                print(f\"Top-left: ({x1}, {y1})\")\n",
    "                print(f\"Bottom-right: ({x2}, {y2})\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"Please complete the rectangle before confirming\")\n",
    "        \n",
    "        # Press 'q' to quit\n",
    "        elif key == ord('q'):\n",
    "            print(\"\\nQuitting without saving\")\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Usage example\n",
    "video_path = camera_1_files_sorted[0]\n",
    "draw_door_area(video_path, save_path=\"door_coordinates_camera1.json\")\n",
    "\n",
    "#video_path = camera_2_files_sorted[0]\n",
    "#draw_door_area(video_path, save_path=\"door_coordinates_camera2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Door coordinates saved to door_coordinates_camera1.json:\n",
    "        Top-left: (1033, 9)\n",
    "        Bottom-right: (1673, 559)\n",
    "\n",
    "\n",
    "Top-left: (459, 2)\n",
    "Bottom-right: (739, 469)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import urllib.request\n",
    "import os\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "class PersonTracker:\n",
    "    def __init__(self):\n",
    "        self.model = YOLO('yolov8x.pt')\n",
    "\n",
    "        # Download and load face cascade file\n",
    "        cascade_file = 'haarcascade_frontalface_default.xml'\n",
    "        if not os.path.exists(cascade_file):\n",
    "            url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
    "            urllib.request.urlretrieve(url, cascade_file)\n",
    "\n",
    "        self.face_cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "        self.unique_persons = []\n",
    "        self.position_history = []\n",
    "        self.track_length = 30\n",
    "\n",
    "        # Tracking parameters\n",
    "        self.similarity_threshold = 0.7\n",
    "        self.position_threshold = 150\n",
    "\n",
    "        # Door zone parameters\n",
    "        self.door_zone = None  # Will be set by user\n",
    "\n",
    "    def process_video(self, video_path):\n",
    "        # Initialize VideoCapture\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Unable to open video file: {video_path}\")\n",
    "            return\n",
    "\n",
    "        frame_count = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"End of video or failed to read frame.\")\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "            print(f\"Processing frame {frame_count}...\")\n",
    "\n",
    "            # Preprocess frame\n",
    "            frame = cv2.resize(frame, (640, 384))\n",
    "\n",
    "            # YOLO Inference\n",
    "            try:\n",
    "                results = self.model(frame)\n",
    "            except Exception as e:\n",
    "                print(f\"Error during inference: {e}\")\n",
    "                break\n",
    "\n",
    "            detections = results[0].boxes.data.cpu().numpy()\n",
    "            print(f\"Detections: {len(detections)}\")\n",
    "\n",
    "            # Draw detections\n",
    "            for det in detections:\n",
    "                x1, y1, x2, y2, conf, cls = det\n",
    "                cv2.rectangle(\n",
    "                    frame,\n",
    "                    (int(x1), int(y1)),\n",
    "                    (int(x2), int(y2)),\n",
    "                    (0, 255, 0),\n",
    "                    2\n",
    "                )\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    f\"{conf:.2f}\",\n",
    "                    (int(x1), int(y1 - 10)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (0, 255, 0),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "            # Display frame\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "tracker = PersonTracker()\n",
    "unique_count = tracker.process_video(video_path)\n",
    "print(f\"Number of unique individuals detected: {unique_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cctv-analysis-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
